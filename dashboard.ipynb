{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "#from keypass import NOAA_api\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score,explained_variance_score\n",
    "from numpy import absolute,mean,std\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling CO2 Sequestration using the Global Ocean Data Analysis Project (GLODAP) \n",
    "\n",
    "[GitHub Repo](https://github.com/ossana1/DATA606_FinalProject)<br><br>\n",
    "[Project Site](https://sites.google.com/s/14-zXY-tR-4ddTR09NcwHH0VdedwqjA0Q/p/1mnouXuUqS3ud_088LqPGmpKfiSUgTiD3/edit?ths=true)\n",
    "\n",
    "### Project Goal: Carbon Dioxide Concentration Modeling to Fill Dataset Gaps \n",
    "\n",
    "The GLODAP v2.2020 dataset has approximately 65% of entries missing $tCO_2$values. The goal of this project is to use a regression ML model to fill the missing entries in the dataset, using measurements of pH, alkalinity, geolocation, temperature, date, etc. as model inputs. \n",
    "\n",
    "Increasing the robustness of this data set could help predict future net carbon dioxide absorption areas which may be at higher risk for earlier ocean acidification than predicted. It may be possible to protect these areas in ways that slow or mitigate the changes in TCO2  that can damage marine life and a valuable food source for mankind. <br>\n",
    "<img src=\"https://raw.githubusercontent.com/ossana1/DATA606_FinalProject/master/images/ProjectMap.png\" \n",
    "     height=\"1627.19\" width=\"1005.12\" >\n",
    "\n",
    "***\n",
    "Model performance on train, test, and validation sets for $tCO_2$ ML random forest regression model ($R^2$ and explained variance of ~0.99 on all sets). The mean square error of the train, test, validation sets were 9.84, 77.0, 68.7, respectively.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ossana1/DATA606_FinalProject/master/images/MLperformance.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A smaller version of the original dataset is available to view  in the first visual. Use this visual to see a condensed version of the data in the data set after the $tCO_2$ is filled with ML RF model.\n",
    "\n",
    "Every 25th row is saved to make the dashboard useable (ie faster). There were 1218966 rows before the trim and 48759 after. There are 33 cruises with <100 datapoints out of 936 cruises, this data loss is acceptable to make the dashboard respond to users in real time.  \n",
    "\n",
    "Select the dataset variable column and year using the dropdowns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/60609760/is-there-a-way-to-import-csv-file-from-github-automatically-to-my-jupyter-notebo (accessed Oct. 08, 2020).\n",
    "\n",
    "#df =pd.read_csv('C:\\\\Users\\\\ossan\\\\DATA606\\\\DATA\\\\TCO2_filled.csv',index_col=0) #ORIGINAL\n",
    "#plotly is too slow with complete set -use this for now \n",
    "url = 'https://raw.githubusercontent.com/ossana1/DATA606_FinalProject/master/data/TCO2_small.csv'\n",
    "df = pd.read_csv(url,index_col=0)\n",
    "dftrim = df \n",
    "#print(len(df))\n",
    "df['year'] =pd.to_numeric( df['year'])\n",
    "df['year'] =df['year'].astype(int)\n",
    "g=df.groupby('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {} # make dictionary of dataframes per year\n",
    "for x,y in g:\n",
    "    frames[x] = y\n",
    "#frames[list(frames.keys())[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make variable list for viusla \n",
    "var = df.columns \n",
    "years = list(frames.keys())\n",
    "list_updatemenus=[];temp_dict={}\n",
    "#make dictionaries for dropdowns for visual\n",
    "for n, year in enumerate(years):\n",
    "    visible = [False] * len(years)\n",
    "    visible[n] = True\n",
    "    temp_dict = dict(label = str(year),method = 'update',\n",
    "                 args = [{'visible': visible},{'title': 'Year %d' % year}])\n",
    "    list_updatemenus.append(temp_dict)\n",
    "    \n",
    "list_c=[];c_dict={}\n",
    "for n, year in enumerate(var):\n",
    "    visible = [False] * len(var)\n",
    "    visible[n] = True\n",
    "    c_dict = dict(label = str(var),method = 'update',\n",
    "                 args = [{'visible': visible}, {'title': var}])\n",
    "    list_c.append(c_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list for nicer formatted columns for visuals \n",
    "col=['Cruise', 'Station',  'Year', 'Month', 'Day', 'Bottom Depth', 'Max Sample Depth', 'Pressure', 'Depth',\n",
    "       'Potential Temperature', 'theta', 'Salinity', 'Potential Temp 0m', 'Potential Temp 1km', 'Potential Temp 2km',\n",
    "       'Potential Temp 3km', 'Neutral Density', 'oxygen', 'Actual O2 Utilization', 'Nitrate', 'Nitrite', 'Silicate',\n",
    "       'Phosphate', 'Total Alkalinity', 'pH at STP', 'pH in Situ', 'tco2']\n",
    "\n",
    "actu=['cruise', 'station', 'year', 'month', 'day', 'bottomdepth', 'maxsampdepth', 'pressure', 'depth',\n",
    "       'temperature', 'theta', 'salinity', 'sigma0', 'sigma1', 'sigma2',\n",
    "       'sigma3', 'gamma', 'oxygen', 'aou', 'nitrate', 'nitrite', 'silicate',\n",
    "       'phosphate', 'talk', 'phts25p0', 'phtsinsitutp', 'tco2']\n",
    "unit=[ '', 'm', 'm','bar', 'm', 'C', 'C', '', 'kg m-3',\n",
    "       'kg m-3', 'kg m-3', 'kg m-3', 'kg m-3', 'umol kg-1', 'umol kg-1', 'umol kg-1','umol kg-1', 'umol kg-1', 'umol kg-1', 'umol kg-1', '', '',\n",
    "       'umol kg-1']\n",
    "def plot_compare_lag(var, year):\n",
    "    #make figure \n",
    "    fig5 =go.Figure(go.Scattergeo(locationmode ='ISO-3',lon=dftrim[\"longitude\"],\n",
    "                                  lat=dftrim[\"latitude\"],#color=var,\n",
    "        mode ='markers',marker = dict(\n",
    "            size = 2, color = dftrim[actu[col.index(var)]], colorscale = 'Inferno',\n",
    "            cmax = df[actu[col.index(var)]].max(),colorbar_title=unit[col.index(var)]) ),\n",
    "    layout= dict(title ='Variable: ' +var + ' | Year:'  + str(year.astype(str)[0:4]))  )\n",
    "    fig5.show()\n",
    "    return fig5 \n",
    "\n",
    "interactive(plot_compare_lag, var=col, \n",
    "            year=list(np.linspace(1984,2019,(2019-1983))),  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## See the changes over the years with this visual. \n",
    "\n",
    "The complete (filled) dataset is first grouped by latitude and longitude and averaged per year. The latitude and longitude of the ending year in the query is used with sklearn BallTree to find (haversine distance) the closest cruise geolocation in the startinng year. The difference between the starting year and end year variable of choice is displayed (end year- start year value). One shortcoming is that depth of the samples are not taken into account at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/ossana1/DATA606_FinalProject/master/data/Groupedlatlongyr.csv'\n",
    "latlong= pd.read_csv(url,index_col=0)\n",
    "latlong.drop(columns=['cruise','station','day','month','Fill','cast'],inplace=True)\n",
    "#clean up columns for labels \n",
    "colu=['Year','Bottom Depth', 'Max Sample Depth', 'Pressure', 'Depth', 'Potential Temperature', 'theta', 'Salinity', 'Potential Temp 0m', 'Potential Temp 1km', 'Potential Temp 2km',\n",
    "       'Potential Temp 3km', 'Neutral Density', 'oxygen', 'Actual O2 Utilization', 'Nitrate', 'Nitrite', 'Silicate',\n",
    "       'Phosphate', 'Total Alkalinity', 'pH at STP', 'pH in Situ', 'tco2']\n",
    "actua=[ 'year', 'bottomdepth', 'maxsampdepth','pressure', 'depth', 'temperature', 'theta', 'salinity', 'sigma0',\n",
    "       'sigma1', 'sigma2', 'sigma3', 'gamma', 'oxygen', 'aou', 'nitrate','nitrite', 'silicate', 'phosphate', 'talk', 'phts25p0', 'phtsinsitutp',\n",
    "       'tco2']\n",
    "\n",
    "unit=[ '', 'm', 'm','bar', 'm', 'C', 'C', '', 'kg m-3',\n",
    "       'kg m-3', 'kg m-3', 'kg m-3', 'kg m-3', 'umol kg-1', 'umol kg-1', 'umol kg-1','umol kg-1', 'umol kg-1', 'umol kg-1', 'umol kg-1', '', '',\n",
    "       'umol kg-1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f2614ff0df440aabc5b160af197b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='var', options=('Year', 'Bottom Depth', 'Max Sample Depth', 'Pressuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "def chang(var,start,end,df):\n",
    "    start_year=latlong[latlong.year ==start].reset_index(); end_year=latlong[latlong.year ==end].reset_index()\n",
    "    query_lats = end_year.latitude;query_lons = end_year.longitude\n",
    "    \n",
    "    varx = actua[colu.index(var)] \n",
    "    #search for closest lat and long \n",
    "    ###https://stackoverflow.com/questions/10549402/kdtree-for-longitude-latitude\n",
    "    bt = BallTree(np.deg2rad(start_year[['latitude', 'longitude']].values), metric='haversine')\n",
    "    distances, indices = bt.query(np.deg2rad(np.c_[query_lats, query_lons]))\n",
    "\n",
    "    i = pd.DataFrame(list(zip(distances,indices)),columns=['distances','indices'])\n",
    "    end_year['compare']  =i.iloc[:,1].astype(int)\n",
    "    end_year['data'] = start_year.loc[end_year.compare,varx].values\n",
    "    end_year['diff'] =(end_year[varx]- end_year['data'])\n",
    "    return end_year\n",
    "\n",
    "def plot_compare_lag(var, startyear,endyear):\n",
    "    change = chang(var,startyear,endyear,latlong)\n",
    "    fig =go.Figure(go.Scattergeo(locationmode ='ISO-3',lon=change[\"longitude\"],\n",
    "                                  lat=change[\"latitude\"],#color=var,\n",
    "        mode ='markers',marker = dict(\n",
    "            size = 4, color = change['diff'], colorscale = 'Inferno',\n",
    "            colorbar_title=' Change' +' '+unit[col.index(var)] ) ), #cmax = 1.5*change['diff'].max(),\n",
    "    layout= dict(title ='Variable Change: ' +var + ' | Start Year:'  + \n",
    "                 str(startyear.astype(str)[0:4]) +'| End Year:'  + \n",
    "                 str(endyear.astype(str)[0:4]))  )\n",
    "    fig.show()\n",
    "    return fig \n",
    "\n",
    "\n",
    "\n",
    "interactive(plot_compare_lag, var=colu, startyear=list(np.linspace(1984,2019,(2019-1983))), \n",
    "            endyear=list(np.linspace(1984,2019,(2019-1983))),)\n",
    "\n",
    "\n",
    "interactive(plot_compare_lag, var=colu, startyear=list(np.linspace(1984,2019,(2019-1983))), \n",
    "            endyear=list(np.linspace(1984,2019,(2019-1983))),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
